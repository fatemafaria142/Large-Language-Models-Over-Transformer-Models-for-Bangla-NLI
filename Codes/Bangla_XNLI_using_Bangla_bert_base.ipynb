{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBRzPyYxNJ0f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,log_loss,jaccard_score,roc_auc_score,classification_report,confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KDmjTaQIf9B",
    "outputId": "5a97145b-b7b6-4950-cbaf-d86fdb7e89a5"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tia5tAEYMaze"
   },
   "source": [
    "### **Dataset link:** https://huggingface.co/datasets/csebuetnlp/xnli_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6h2Br0UrIFIW"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csebuetnlp/xnli_bn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6394LGB9I4ag",
    "outputId": "2ad1fae7-55bb-4d82-d52a-26f147798eef"
   },
   "outputs": [],
   "source": [
    "# Access train, test, and validation splits\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "validation_data = dataset['validation']\n",
    "\n",
    "# Optional: You can also print the number of examples in each split\n",
    "print(f\"Number of examples in train set: {len(train_data)}\")\n",
    "print(f\"Number of examples in test set: {len(test_data)}\")\n",
    "print(f\"Number of examples in validation set: {len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sLPWzK9EJynU",
    "outputId": "d47db946-17e2-48cc-ac67-c2fb73468f65"
   },
   "outputs": [],
   "source": [
    "# Access train data\n",
    "train_data = dataset['train']\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "df_train = pd.DataFrame(train_data)  \n",
    "\n",
    "# Map numeric labels to textual representations\n",
    "label_map = {\n",
    "    0: 'Contradiction',\n",
    "    1: 'Entailment',\n",
    "    2: 'Neutral'\n",
    "}\n",
    "\n",
    "df_train['label'] = df_train['label'].map(label_map)\n",
    "\n",
    "# Display the modified DataFrame with the new column\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fT-FFrYjJdaS",
    "outputId": "4b0608d9-7505-4363-8cc3-01693a4326f6"
   },
   "outputs": [],
   "source": [
    "# Access test data\n",
    "test_data = dataset['test']\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "# Map numeric labels to textual representations\n",
    "label_map = {\n",
    "    0: 'Contradiction',\n",
    "    1: 'Entailment',\n",
    "    2: 'Neutral'\n",
    "}\n",
    "\n",
    "df_test['label'] = df_test['label'].map(label_map)\n",
    "\n",
    "# Display the modified DataFrame with the new column\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "F8CjrWGAKOpP",
    "outputId": "7ac94d3e-f22d-49c0-ddd9-8926ea8454c5"
   },
   "outputs": [],
   "source": [
    "# Access validation data\n",
    "validation_data = dataset['validation']\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "df_validation = pd.DataFrame(validation_data)\n",
    "\n",
    "# Map numeric labels to textual representations\n",
    "label_map = {\n",
    "    0: 'Contradiction',\n",
    "    1: 'Entailment',\n",
    "    2: 'Neutral'\n",
    "}\n",
    "\n",
    "df_validation['label'] = df_validation['label'].map(label_map)\n",
    "\n",
    "# Display the modified DataFrame with the new column\n",
    "df_validation.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8vIwkssRyQ-"
   },
   "source": [
    "# **Visualization of Label Distribution in Train dataset**\n",
    "* Contradiction - 0\n",
    "* Entailment - 1\n",
    "* Neutral - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "y-wuShbSREsG",
    "outputId": "927185be-bda7-4920-c5e9-8f90c0068fc6"
   },
   "outputs": [],
   "source": [
    "label_counts = df_train['label'].value_counts()\n",
    "\n",
    "# Define custom colors for the bars ('e', 'c', and 'n')\n",
    "custom_colors = ['#8cbfff', '#d62728','#d4ffcc']\n",
    "\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Create bar plot with grid\n",
    "bars = plt.bar(label_counts.index, label_counts.values, color=custom_colors)\n",
    "#plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Label Distribution', fontdict=font)\n",
    "plt.xlabel('Label', fontdict=font)\n",
    "plt.ylabel('Count', fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(label_counts.index, label_counts.index, fontdict=font)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "\n",
    "# Adding annotations (count values) on top of each bar\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', fontdict=font)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BLyZA3kSd84"
   },
   "source": [
    "# **Visualization of Label Distribution in Test dataset**\n",
    "* Contradiction - 0\n",
    "* Entailment - 1\n",
    "* Neutral - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "JOiar7ipSbA_",
    "outputId": "6f9a161e-88d0-47d6-804d-cfb832f3b9cb"
   },
   "outputs": [],
   "source": [
    "label_counts = df_test['label'].value_counts()\n",
    "\n",
    "# Define custom colors for the bars ('e', 'c', and 'n')\n",
    "custom_colors = ['#8cbfff', '#d62728','#d4ffcc']\n",
    "\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Create bar plot with grid\n",
    "bars = plt.bar(label_counts.index, label_counts.values, color=custom_colors)\n",
    "#plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Label Distribution', fontdict=font)\n",
    "plt.xlabel('Label', fontdict=font)\n",
    "plt.ylabel('Count', fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(label_counts.index, label_counts.index, fontdict=font)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "\n",
    "# Adding annotations (count values) on top of each bar\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', fontdict=font)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWjV05iSrV2"
   },
   "source": [
    "# **Visualization of Label Distribution in Validation dataset**\n",
    "* Contradiction - 0\n",
    "* Entailment - 1\n",
    "* Neutral - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "3Nn6NpSGSpKv",
    "outputId": "3290366a-7d5c-4ecb-cf06-127b3c0d31c7"
   },
   "outputs": [],
   "source": [
    "label_counts = df_validation['label'].value_counts()\n",
    "\n",
    "# Define custom colors for the bars ('e', 'c', and 'n')\n",
    "custom_colors = ['#8cbfff', '#d62728','#d4ffcc']\n",
    "\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Create bar plot with grid\n",
    "bars = plt.bar(label_counts.index, label_counts.values, color=custom_colors)\n",
    "#plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Label Distribution', fontdict=font)\n",
    "plt.xlabel('Label', fontdict=font)\n",
    "plt.ylabel('Count', fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(label_counts.index, label_counts.index, fontdict=font)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "\n",
    "# Adding annotations (count values) on top of each bar\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', fontdict=font)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA5tBs-uTHKc"
   },
   "source": [
    "# **Visualization of Premise Length Distribution in Train Dataset**\n",
    "## **sentence1 length checking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "O02DpO2LTC1y",
    "outputId": "fe0504e4-906a-4903-caf5-257e3ee134fc"
   },
   "outputs": [],
   "source": [
    "# Visualize premise length distribution\n",
    "premise_lengths = df_train['sentence1'].apply(lambda x: len(x.split()))\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "custom_colors = ['#fc9292']\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(premise_lengths, bins=15, color=custom_colors,edgecolor='black' ,alpha=0.7)\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Premise Length Distribution',fontdict=font)\n",
    "plt.xlabel('Length of Premise',fontdict=font)\n",
    "plt.ylabel('Numbers of Premise',fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(fontname='Serif', fontsize=10)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "#plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcq6Ox5_T-eI"
   },
   "source": [
    "# **Visualization of Premise Length Distribution in Test Dataset**\n",
    "## **sentence1 length checking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "zoejjr4gT4RR",
    "outputId": "e5213014-c0aa-4149-9c88-3cd684c6ad37"
   },
   "outputs": [],
   "source": [
    "# Visualize premise length distribution\n",
    "premise_lengths = df_test['sentence1'].apply(lambda x: len(x.split()))\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "custom_colors = ['#fc9292']\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(premise_lengths, bins=15, color=custom_colors,edgecolor='black' ,alpha=0.7)\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Premise Length Distribution',fontdict=font)\n",
    "plt.xlabel('Length of Premise',fontdict=font)\n",
    "plt.ylabel('Numbers of Premise',fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(fontname='Serif', fontsize=10)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "#plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM7ClLAlUMKW"
   },
   "source": [
    "# **Visualization of Premise Length Distribution in Validation Dataset**\n",
    "## **sentence1 length checking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "7P9zOgW6T4Ze",
    "outputId": "4b0e27a4-1aa0-4a52-bc19-d4023914ecc6"
   },
   "outputs": [],
   "source": [
    "# Visualize premise length distribution\n",
    "premise_lengths = df_validation['sentence1'].apply(lambda x: len(x.split()))\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "custom_colors = ['#fc9292']\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(premise_lengths, bins=15, color=custom_colors,edgecolor='black' ,alpha=0.7)\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Premise Length Distribution',fontdict=font)\n",
    "plt.xlabel('Length of Premise',fontdict=font)\n",
    "plt.ylabel('Numbers of Premise',fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(fontname='Serif', fontsize=10)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "#plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoM8l5aCUa0L"
   },
   "source": [
    "# **Dataset Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvhWp-DvUVpd",
    "outputId": "227fa657-7292-431c-e9fe-04d0b279226c"
   },
   "outputs": [],
   "source": [
    "print(f\"Train Dataset Length: {len(df_train)}\")\n",
    "print(f\"Test Dataset Length: {len(df_test)}\")\n",
    "print(f\"Validation Dataset Length: {len(df_validation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEsnFWBTVmLS"
   },
   "source": [
    "# **Null value checking in Train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xK9pVl81UVtj",
    "outputId": "3f64a9b3-626d-4ab6-d37b-5cf759743034"
   },
   "outputs": [],
   "source": [
    "# Check for null values in 'premise', 'hypothesis' and\t'label' columns\n",
    "null_premise = df_train['sentence1'].isnull().sum()\n",
    "null_hypothesis = df_train['sentence2'].isnull().sum()\n",
    "null_label = df_train['label'].isnull().sum()\n",
    "\n",
    "\n",
    "print(f\"Null values in 'sentence1': {null_premise}\")\n",
    "print(f\"Null values in 'sentence2': {null_hypothesis}\")\n",
    "print(f\"Null values in 'label': {null_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUwiQtiXVrwU"
   },
   "source": [
    "# **Null value checking in Test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noFsoPvtVp52",
    "outputId": "c7998a8a-756a-4897-cf41-565d78951a75"
   },
   "outputs": [],
   "source": [
    "# Check for null values in 'premise', 'hypothesis' and\t'label' columns\n",
    "null_premise = df_test['sentence1'].isnull().sum()\n",
    "null_hypothesis = df_test['sentence2'].isnull().sum()\n",
    "null_label = df_test['label'].isnull().sum()\n",
    "\n",
    "\n",
    "print(f\"Null values in 'sentence1': {null_premise}\")\n",
    "print(f\"Null values in 'sentence2': {null_hypothesis}\")\n",
    "print(f\"Null values in 'label': {null_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6NuC1kuV2vg"
   },
   "source": [
    "# **Null value checking in Validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAqnTK22Vp-G",
    "outputId": "1a81b399-fd19-4de7-a4fc-e64ea7956591"
   },
   "outputs": [],
   "source": [
    "# Check for null values in 'premise', 'hypothesis' and\t'label' columns\n",
    "null_premise = df_validation['sentence1'].isnull().sum()\n",
    "null_hypothesis = df_validation['sentence2'].isnull().sum()\n",
    "null_label = df_validation['label'].isnull().sum()\n",
    "\n",
    "\n",
    "print(f\"Null values in 'sentence1': {null_premise}\")\n",
    "print(f\"Null values in 'sentence2': {null_hypothesis}\")\n",
    "print(f\"Null values in 'label': {null_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug6ZBvbDXZyp"
   },
   "source": [
    "# **Bangla-bert-base model and its tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "9ab239b4dee74a0ab9b86fe02f070c22",
      "405a2f699c984ed4b3c908e9845228dc",
      "4057e877a44f4115a9784fea60e7d684",
      "4b19e2a6518b4de2ad6cdebbd03582a4",
      "cda9f79a5bad421ba5647e20a6c351ed",
      "13ed7e116ffe4a629c2a3d540e9500cb",
      "1732fce6433b4e998578ad667bea2683",
      "0866cb8fd2b2438689a0c182f6d97a6a",
      "bc70958c339c4264a2c78caf4e3211c3",
      "71524abe6fa243c6b1a418dd956f2646",
      "3665cd15ea9f48c79f3a8538adb9ae51",
      "d81f68e9e15140f3a60db82b937c48ab",
      "d99e5e68733b42e6b057fb80e536365b",
      "3515fc20aacb4f41861a4ff0ec2a6f4e",
      "c43679ae43d24b64aa45ac9d5ee24974",
      "019c76db50174603a7d3aa3d9795f93d",
      "44ca99e73770450dae9f546a212b9fd6",
      "8539c5ccbdc845fbb1cb824c7e29d5dd",
      "e0f3db97e1cb4528b89e6008a593d6f0",
      "67984599f0ea4ddf836dabe927e38e03",
      "1d54bcc355e9486dab1cdbd0021cd1ce",
      "ab7a90644cbf41aea5355407a0686c19",
      "e23dfa720481412eb42def1597b5672b",
      "98dee9ce3b79420ca44f1d7d44b56c0d",
      "499c5c2226834c55b268453548b0be7c",
      "6d4e6faea2f24b839891976ff40099e2",
      "d331977a48204524a0a29d88161eba3a",
      "b432242c3b4449e8b0b11a3695e67c3c",
      "e0b119eb336d45f4b21954701d41bf51",
      "32a092920bb54dd0ae0a6a5bf06535f0",
      "1abd9e36cdba4f43b95b46b2dab80429",
      "cd07b9365ee946b389a6e51af0cb2d62",
      "2b91e9e3a28d45c7859c7ea84432e488"
     ]
    },
    "id": "89j9mSDuXYVC",
    "outputId": "7811209b-374b-4f7d-815e-cc1e7fe642dd"
   },
   "outputs": [],
   "source": [
    "# Model loading\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "\n",
    "num_classes = 3  #number of classes in our dataset\n",
    "\n",
    "model_name = \"sagorsarker/bangla-bert-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33_47eAvYAq7",
    "outputId": "423f7abc-ec6d-4c04-ed71-5e0e46dc749e"
   },
   "outputs": [],
   "source": [
    "# Place model on the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ra5idwcXGnr"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DEdDfUQXmSP"
   },
   "source": [
    "# **Custom Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KS9BMVKkI2Q"
   },
   "outputs": [],
   "source": [
    "class NaturalLanguageInferenceDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.label_map = {'Contradiction': 0, 'Entailment': 1, 'Neutral': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        premise = self.data.iloc[idx]['sentence1']\n",
    "        hypothesis = self.data.iloc[idx]['sentence2']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        # Map label to integer\n",
    "        label_id = self.label_map[label]\n",
    "\n",
    "        # Tokenize premise and hypothesis separately\n",
    "        encoded_dict_premise = self.tokenizer.encode_plus(\n",
    "            premise,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length // 2,  # Allocate half of the max_length to each\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        encoded_dict_hypothesis = self.tokenizer.encode_plus(\n",
    "            hypothesis,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length // 2,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Concatenate input_ids and attention_masks\n",
    "        input_ids = torch.cat((encoded_dict_premise['input_ids'], encoded_dict_hypothesis['input_ids']), dim=1)\n",
    "        attention_mask = torch.cat((encoded_dict_premise['attention_mask'], encoded_dict_hypothesis['attention_mask']), dim=1)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids.squeeze(),\n",
    "            'attention_mask': attention_mask.squeeze(),\n",
    "            'label': torch.tensor(label_id, dtype=torch.long)  # Use mapped label_id\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lb-YGHWDXp1o"
   },
   "source": [
    "# **Custom dataset and dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmY-Js5uWIQR"
   },
   "outputs": [],
   "source": [
    "# Define custom datasets\n",
    "train_dataset = NaturalLanguageInferenceDataset(df_train, tokenizer)\n",
    "val_dataset = NaturalLanguageInferenceDataset(df_validation, tokenizer)\n",
    "test_dataset = NaturalLanguageInferenceDataset(df_test, tokenizer)\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqS_EvPQYvbP"
   },
   "source": [
    "# **Train Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFgbykugWIUc",
    "outputId": "45a10c40-021a-4d35-a824-9846265cf9ed"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in train_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WOw8GpDYxfu"
   },
   "source": [
    "# **Test Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wq5TW7iYYZLV",
    "outputId": "df09e842-e8f7-4f0f-8cde-38c5940ff0c9"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in test_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMKWxh1cY1VY"
   },
   "source": [
    "# **Validation Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IoCxG4aYZP8",
    "outputId": "9d165028-1f04-4003-efaf-f0fe311e78a4"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in val_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xya2GAiZY7Dc"
   },
   "source": [
    "# **Train Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFw3haCPYZT0",
    "outputId": "29bbb182-14c0-4e91-f926-b2fabd69e7a0"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in train_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = tokenizer.decode(labels.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Labels:\", decoded_labels)\n",
    "\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaFuSRr4Y8zq"
   },
   "source": [
    "# **Test Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHWs5hbMYjoR",
    "outputId": "67546eda-05dc-470c-c223-2e60caf3a611"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in test_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = tokenizer.decode(labels.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Labels:\", decoded_labels)\n",
    "\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLjTMnmHZBY8"
   },
   "source": [
    "# **Validation Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6erEF_UnYm2S",
    "outputId": "e6cec093-aedb-43e9-846c-4fe51f647917"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in val_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = tokenizer.decode(labels.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Labels:\", decoded_labels)\n",
    "\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKfX8TKTagym"
   },
   "source": [
    "# **Optimizer and Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzJPPnvEZEDg"
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIciuBBecEJs"
   },
   "source": [
    "# **Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6EHO17FZEGq",
    "outputId": "dc1456aa-a947-400e-c60d-e09fe6bff0d8"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 1\n",
    "gradient_accumulation_steps = 4  # Accumulate gradients over 4 steps\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start time of the epoch\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    for batch_idx, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Logits directly from the model output\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Average training loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    # Wrap val_loader with tqdm for progress bar\n",
    "    for batch in tqdm(val_loader, desc=f'Validation', leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Logits directly from the model output\n",
    "\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "\n",
    "        val_preds.extend(predicted.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Calculate and print epoch training time\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} completed in {epoch_time // 60:.0f}m {epoch_time % 60:.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMAZ3gxRcHln"
   },
   "source": [
    "# **Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fo5cj9stZJFB",
    "outputId": "8aa1b29d-ef30-4faa-a7af-571f8bc820bb"
   },
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "test_labels = []\n",
    "test_probs = []  # Store predicted probabilities\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Assuming our model directly outputs logits\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)  # Softmax to get probabilities\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_probs.extend(probabilities.cpu().numpy())  # Append predicted probabilities\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "test_precision = precision_score(test_labels, test_preds, average='macro')\n",
    "test_recall = recall_score(test_labels, test_preds, average='macro')\n",
    "test_f1 = f1_score(test_labels, test_preds, average='macro')\n",
    "test_jaccard_score = jaccard_score(test_labels, test_preds, average='macro')\n",
    "test_log_loss = log_loss(test_labels, test_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRqYwRUaXgXY",
    "outputId": "36706d27-3a3b-465a-a916-2d274fca2b44"
   },
   "outputs": [],
   "source": [
    "print(test_preds)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIXup--IZ309"
   },
   "source": [
    "# **Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVcXiSQZZ13m",
    "outputId": "4882c360-52c3-46ce-ca1f-e47595b082f1"
   },
   "outputs": [],
   "source": [
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Test Jaccard Score: {test_jaccard_score}')\n",
    "print(f'Test Log Loss: {test_log_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0jb96A-XMov"
   },
   "source": [
    "* For a multiclass problem, sensitivity and specificity are typically calculated using a one-vs-all (or one-vs-rest) approach. This means treating each class as the positive class once while aggregating the others as the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4o8mMf0iW_lT",
    "outputId": "1e0387a5-8810-409e-9e80-e51e0237baa8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def sensitivity_score_multiclass(y_true, y_pred, class_label):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    true_positives = cm[class_label, class_label]\n",
    "    actual_positives = sum(cm[class_label, :])\n",
    "    return true_positives / actual_positives if actual_positives != 0 else 0\n",
    "\n",
    "num_classes = 3  # We have 3 classes (adjust according to your dataset)\n",
    "\n",
    "sensitivity_scores = []\n",
    "for class_label in range(num_classes):\n",
    "    sensitivity = sensitivity_score_multiclass(test_labels, test_preds, class_label)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "\n",
    "print(\"Sensitivity (Recall) for each class:\", sensitivity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qw8I0V_OXXYk",
    "outputId": "3873775d-b42e-4d63-82bc-aef0a31cb52a"
   },
   "outputs": [],
   "source": [
    "def specificity_score_multiclass(y_true, y_pred, class_label):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    true_negatives = sum(sum(cm)) - sum(cm[class_label, :]) - sum(cm[:, class_label]) + cm[class_label, class_label]\n",
    "    actual_negatives = sum(sum(cm)) - sum(cm[class_label, :])\n",
    "    return true_negatives / actual_negatives if actual_negatives != 0 else 0\n",
    "specificity_scores = []\n",
    "for class_label in range(num_classes):\n",
    "    specificity = specificity_score_multiclass(test_labels, test_preds, class_label)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "print(\"Specificity for each class:\", specificity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgaso22xeD5C",
    "outputId": "21194855-c90b-4c46-b77c-cc9fb3de7167"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# Convert labels to one-hot encoded format\n",
    "label_binarizer = LabelBinarizer()\n",
    "test_labels_one_hot = label_binarizer.fit_transform(test_labels)\n",
    "\n",
    "# Reshape the one-hot encoded labels\n",
    "num_classes = len(label_binarizer.classes_)\n",
    "test_labels_one_hot = test_labels_one_hot.reshape(-1, num_classes)\n",
    "\n",
    "# Creating a 2D array for test_preds\n",
    "num_samples = len(test_preds)\n",
    "num_classes = len(label_binarizer.classes_)\n",
    "formatted_preds = [[0] * num_classes for _ in range(num_samples)]\n",
    "for i, pred in enumerate(test_preds):\n",
    "    formatted_preds[i][pred] = 1\n",
    "\n",
    "# Calculate ROC AUC score for multiclass classification\n",
    "test_roc_auc_score = roc_auc_score(test_labels_one_hot, formatted_preds, average='macro', multi_class='ovo')\n",
    "print(\"Test ROC AUC Score:\", test_roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NVQ0W5LZJM5",
    "outputId": "fb4fa694-1066-48ee-bcc2-69070bcec640"
   },
   "outputs": [],
   "source": [
    "# Mapping numeric labels to category names\n",
    "label_map = {0: 'Entailment', 1: 'Contradiction', 2: 'Neutral'}\n",
    "\n",
    "# Convert numeric predictions to label names\n",
    "predicted_labels = [label_map[pred] for pred in test_preds]\n",
    "true_labels = [label_map[label] for label in test_labels]\n",
    "\n",
    "# Generate and print the classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "# Classification Report:\n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "# Contradiction       0.73      0.64      0.68      1631\n",
    "#    Entailment       0.71      0.75      0.73      1630\n",
    "#       Neutral       0.63      0.67      0.65      1634\n",
    "\n",
    "#      accuracy                           0.68      4895\n",
    "#     macro avg       0.69      0.68      0.68      4895\n",
    "#  weighted avg       0.69      0.68      0.68      4895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9ulwJOfaMyD"
   },
   "source": [
    "# **Confusion Matrix for MultiNLI Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "T3RZGUFBZJQR",
    "outputId": "734e1c2b-29fd-4776-e23b-c49ffda932f2"
   },
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(\"blend:#7AB,#EDA\", as_cmap=True) # Modify the number based on number of classes in the dataset\n",
    "#sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,\n",
    "                      xticklabels=['Contradiction', 'Entailment', 'Neutral'], yticklabels=['Contradiction', 'Entailment', 'Neutral'],annot_kws={\"family\": \"Serif\", 'size': 12, 'color':'black'})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font)\n",
    "heatmap.set_ylabel('True Labels', fontdict=font)\n",
    "heatmap.set_title('Natural Language Inference on \\n XNLI Dataset', fontdict=font)\n",
    "\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=10)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=10)\n",
    "\n",
    "# Create a color bar to indicate the scale\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Count', fontdict=font)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "plt.savefig('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\CM\\\\cm\\\\XNLI_BERTbase___confusion_matrix.pdf') # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dY4JWgMxaZiJ"
   },
   "source": [
    "# **Save results to a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3enaoA8nZQhE"
   },
   "outputs": [],
   "source": [
    "# Combine the lists into a DataFrame\n",
    "data = {'Sentence1': df_test['sentence1'],\n",
    "        'Sentence2': df_test['sentence2'],\n",
    "        'True_Labels': df_test['label'],\n",
    "        'Predicted_Labels': test_preds}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\CM\\\\cm\\\\predicted_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OewdOJGZFN-"
   },
   "source": [
    "# **Save the model and its tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zca-M5R6ZQ6E",
    "outputId": "8f23ec8d-919b-4cb4-891b-1266183db7c4"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\CM\\\\cm\\\\NLI_Bangla-bert-base_Model.pt')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\CM\\\\cm\\\\NLI_Bangla-bert-base_Tokenizer.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Co55vDWHZKb6"
   },
   "source": [
    "# **Load the model and its tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPIG5hI6ZSMN",
    "outputId": "5a5c5416-8a1b-4b23-c23f-e3359084a955"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model.from_pretrained('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\CM\\\\cm\\\\NLI_Bangla-bert-base_Model.pt')\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer.from_pretrained('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\CM\\\\cm\\\\NLI_Bangla-bert-base_Tokenizer.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019c76db50174603a7d3aa3d9795f93d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0866cb8fd2b2438689a0c182f6d97a6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13ed7e116ffe4a629c2a3d540e9500cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1732fce6433b4e998578ad667bea2683": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1abd9e36cdba4f43b95b46b2dab80429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d54bcc355e9486dab1cdbd0021cd1ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b91e9e3a28d45c7859c7ea84432e488": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32a092920bb54dd0ae0a6a5bf06535f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3515fc20aacb4f41861a4ff0ec2a6f4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0f3db97e1cb4528b89e6008a593d6f0",
      "max": 660393036,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67984599f0ea4ddf836dabe927e38e03",
      "value": 660393036
     }
    },
    "3665cd15ea9f48c79f3a8538adb9ae51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4057e877a44f4115a9784fea60e7d684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0866cb8fd2b2438689a0c182f6d97a6a",
      "max": 491,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc70958c339c4264a2c78caf4e3211c3",
      "value": 491
     }
    },
    "405a2f699c984ed4b3c908e9845228dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13ed7e116ffe4a629c2a3d540e9500cb",
      "placeholder": "",
      "style": "IPY_MODEL_1732fce6433b4e998578ad667bea2683",
      "value": "config.json: 100%"
     }
    },
    "44ca99e73770450dae9f546a212b9fd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "499c5c2226834c55b268453548b0be7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32a092920bb54dd0ae0a6a5bf06535f0",
      "max": 2237676,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1abd9e36cdba4f43b95b46b2dab80429",
      "value": 2237676
     }
    },
    "4b19e2a6518b4de2ad6cdebbd03582a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71524abe6fa243c6b1a418dd956f2646",
      "placeholder": "",
      "style": "IPY_MODEL_3665cd15ea9f48c79f3a8538adb9ae51",
      "value": " 491/491 [00:00&lt;00:00, 24.6kB/s]"
     }
    },
    "67984599f0ea4ddf836dabe927e38e03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6d4e6faea2f24b839891976ff40099e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd07b9365ee946b389a6e51af0cb2d62",
      "placeholder": "",
      "style": "IPY_MODEL_2b91e9e3a28d45c7859c7ea84432e488",
      "value": " 2.24M/2.24M [00:00&lt;00:00, 12.6MB/s]"
     }
    },
    "71524abe6fa243c6b1a418dd956f2646": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8539c5ccbdc845fbb1cb824c7e29d5dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98dee9ce3b79420ca44f1d7d44b56c0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b432242c3b4449e8b0b11a3695e67c3c",
      "placeholder": "",
      "style": "IPY_MODEL_e0b119eb336d45f4b21954701d41bf51",
      "value": "vocab.txt: 100%"
     }
    },
    "9ab239b4dee74a0ab9b86fe02f070c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_405a2f699c984ed4b3c908e9845228dc",
       "IPY_MODEL_4057e877a44f4115a9784fea60e7d684",
       "IPY_MODEL_4b19e2a6518b4de2ad6cdebbd03582a4"
      ],
      "layout": "IPY_MODEL_cda9f79a5bad421ba5647e20a6c351ed"
     }
    },
    "ab7a90644cbf41aea5355407a0686c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b432242c3b4449e8b0b11a3695e67c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc70958c339c4264a2c78caf4e3211c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c43679ae43d24b64aa45ac9d5ee24974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d54bcc355e9486dab1cdbd0021cd1ce",
      "placeholder": "",
      "style": "IPY_MODEL_ab7a90644cbf41aea5355407a0686c19",
      "value": " 660M/660M [00:06&lt;00:00, 230MB/s]"
     }
    },
    "cd07b9365ee946b389a6e51af0cb2d62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cda9f79a5bad421ba5647e20a6c351ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d331977a48204524a0a29d88161eba3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d81f68e9e15140f3a60db82b937c48ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d99e5e68733b42e6b057fb80e536365b",
       "IPY_MODEL_3515fc20aacb4f41861a4ff0ec2a6f4e",
       "IPY_MODEL_c43679ae43d24b64aa45ac9d5ee24974"
      ],
      "layout": "IPY_MODEL_019c76db50174603a7d3aa3d9795f93d"
     }
    },
    "d99e5e68733b42e6b057fb80e536365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44ca99e73770450dae9f546a212b9fd6",
      "placeholder": "",
      "style": "IPY_MODEL_8539c5ccbdc845fbb1cb824c7e29d5dd",
      "value": "model.safetensors: 100%"
     }
    },
    "e0b119eb336d45f4b21954701d41bf51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0f3db97e1cb4528b89e6008a593d6f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e23dfa720481412eb42def1597b5672b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98dee9ce3b79420ca44f1d7d44b56c0d",
       "IPY_MODEL_499c5c2226834c55b268453548b0be7c",
       "IPY_MODEL_6d4e6faea2f24b839891976ff40099e2"
      ],
      "layout": "IPY_MODEL_d331977a48204524a0a29d88161eba3a"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
